{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24fdf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "class RecommenderEvaluator:\n",
    "    \"\"\"\n",
    "    Évaluateur pour les systèmes de recommandation\n",
    "    Implémente plusieurs métriques d'évaluation courantes en recommandation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='content_based_model.pkl'):\n",
    "        \"\"\"\n",
    "        Initialise l'évaluateur avec le modèle à évaluer\n",
    "        \n",
    "        Args:\n",
    "            model_path: Chemin vers le fichier du modèle sauvegardé\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model_data = None\n",
    "        self.test_data = None\n",
    "        self.train_data = None\n",
    "        self.recommendations = None\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Charge le modèle entraîné\n",
    "        \"\"\"\n",
    "        print(f\"Chargement du modèle depuis {self.model_path}...\")\n",
    "        with open(self.model_path, 'rb') as f:\n",
    "            self.model_data = pickle.load(f)\n",
    "            \n",
    "        print(\"Modèle chargé!\")\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        \"\"\"\n",
    "        Charge les données de test\n",
    "        \"\"\"\n",
    "        print(\"Chargement des données de test...\")\n",
    "        self.test_data = pd.read_csv('interactions_test.csv')\n",
    "        self.train_data = pd.read_csv('interactions_train.csv')\n",
    "        print(f\"Données de test chargées: {self.test_data.shape}\")\n",
    "        \n",
    "    def generate_recommendations(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Génère des recommandations pour tous les utilisateurs dans les données de test\n",
    "        \n",
    "        Args:\n",
    "            top_n: Nombre de recommandations par utilisateur\n",
    "        \"\"\"\n",
    "        print(f\"Génération des recommandations (top-{top_n})...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Obtenir la liste des utilisateurs uniques dans les données de test\n",
    "        test_users = self.test_data['user_id'].unique()\n",
    "        \n",
    "        all_recommendations = []\n",
    "        \n",
    "        # Pour chaque utilisateur de test\n",
    "        for user_id in test_users:\n",
    "            # Vérifier si l'utilisateur a un profil\n",
    "            if user_id in self.model_data['user_profiles'].index:\n",
    "                # Récupérer le profil de l'utilisateur\n",
    "                user_profile = self.model_data['user_profiles'].loc[user_id].values.reshape(1, -1)\n",
    "                \n",
    "                # Calculer la similarité entre le profil et toutes les vidéos\n",
    "                scores = np.dot(user_profile, self.model_data['content_features'].values.T)[0]\n",
    "                \n",
    "                # Créer un DataFrame avec les scores\n",
    "                user_recs = pd.DataFrame({\n",
    "                    'user_id': user_id,\n",
    "                    'video_id': self.model_data['content_features'].index,\n",
    "                    'score': scores\n",
    "                })\n",
    "                \n",
    "                # Exclure les vidéos déjà vues dans l'ensemble d'entraînement\n",
    "                seen_videos = self.train_data[self.train_data['user_id'] == user_id]['video_id'].values\n",
    "                user_recs = user_recs[~user_recs['video_id'].isin(seen_videos)]\n",
    "                \n",
    "                # Trier par score et prendre les top_n\n",
    "                user_recs = user_recs.sort_values('score', ascending=False).head(top_n)\n",
    "                \n",
    "                all_recommendations.append(user_recs)\n",
    "        \n",
    "        # Concaténer toutes les recommandations\n",
    "        self.recommendations = pd.concat(all_recommendations, ignore_index=True)\n",
    "        \n",
    "        print(f\"Recommandations générées: {self.recommendations.shape}\")\n",
    "        print(f\"Temps d'exécution: {time.time() - start_time:.2f} secondes\")\n",
    "        \n",
    "        # Sauvegarder les recommandations\n",
    "        self.recommendations.to_csv('content_based_recommendations.csv', index=False)\n",
    "    \n",
    "    def calculate_precision_at_k(self, k=10):\n",
    "        \"\"\"\n",
    "        Calcule la précision@k pour les recommandations\n",
    "        \n",
    "        Args:\n",
    "            k: Nombre de recommandations à considérer\n",
    "            \n",
    "        Returns:\n",
    "            Précision moyenne à k\n",
    "        \"\"\"\n",
    "        print(f\"Calcul de la précision@{k}...\")\n",
    "        \n",
    "        precision_scores = []\n",
    "        \n",
    "        # Pour chaque utilisateur dans les recommandations\n",
    "        for user_id in self.recommendations['user_id'].unique():\n",
    "            # Obtenir les top-k recommandations pour cet utilisateur\n",
    "            user_recs = self.recommendations[self.recommendations['user_id'] == user_id].head(k)\n",
    "            recommended_items = set(user_recs['video_id'].values)\n",
    "            \n",
    "            # Obtenir les items pertinents (interactions positives) pour cet utilisateur dans le test\n",
    "            relevant_items = set(self.test_data[(self.test_data['user_id'] == user_id) & \n",
    "                                               (self.test_data['positive_interaction'] == 1)]['video_id'].values)\n",
    "            \n",
    "            # Calculer la précision pour cet utilisateur\n",
    "            if len(recommended_items) > 0:\n",
    "                precision = len(recommended_items.intersection(relevant_items)) / len(recommended_items)\n",
    "                precision_scores.append(precision)\n",
    "        \n",
    "        # Calculer la précision moyenne\n",
    "        mean_precision = np.mean(precision_scores) if precision_scores else 0\n",
    "        \n",
    "        return mean_precision\n",
    "    \n",
    "    def calculate_recall_at_k(self, k=10):\n",
    "        \"\"\"\n",
    "        Calcule le rappel@k pour les recommandations\n",
    "        \n",
    "        Args:\n",
    "            k: Nombre de recommandations à considérer\n",
    "            \n",
    "        Returns:\n",
    "            Rappel moyen à k\n",
    "        \"\"\"\n",
    "        print(f\"Calcul du rappel@{k}...\")\n",
    "        \n",
    "        recall_scores = []\n",
    "        \n",
    "        # Pour chaque utilisateur dans les recommandations\n",
    "        for user_id in self.recommendations['user_id'].unique():\n",
    "            # Obtenir les top-k recommandations pour cet utilisateur\n",
    "            user_recs = self.recommendations[self.recommendations['user_id'] == user_id].head(k)\n",
    "            recommended_items = set(user_recs['video_id'].values)\n",
    "            \n",
    "            # Obtenir les items pertinents (interactions positives) pour cet utilisateur dans le test\n",
    "            relevant_items = set(self.test_data[(self.test_data['user_id'] == user_id) & \n",
    "                                               (self.test_data['positive_interaction'] == 1)]['video_id'].values)\n",
    "            \n",
    "            # Calculer le rappel pour cet utilisateur\n",
    "            if len(relevant_items) > 0:\n",
    "                recall = len(recommended_items.intersection(relevant_items)) / len(relevant_items)\n",
    "                recall_scores.append(recall)\n",
    "        \n",
    "        # Calculer le rappel moyen\n",
    "        mean_recall = np.mean(recall_scores) if recall_scores else 0\n",
    "        \n",
    "        return mean_recall\n",
    "    \n",
    "    def calculate_ndcg_at_k(self, k=10):\n",
    "        \"\"\"\n",
    "        Calcule le NDCG@k (Normalized Discounted Cumulative Gain) pour les recommandations\n",
    "        \n",
    "        Args:\n",
    "            k: Nombre de recommandations à considérer\n",
    "            \n",
    "        Returns:\n",
    "            NDCG moyen à k\n",
    "        \"\"\"\n",
    "        print(f\"Calcul du NDCG@{k}...\")\n",
    "        \n",
    "        ndcg_scores = []\n",
    "        \n",
    "        # Pour chaque utilisateur dans les recommandations\n",
    "        for user_id in self.recommendations['user_id'].unique():\n",
    "            # Obtenir les top-k recommandations pour cet utilisateur\n",
    "            user_recs = self.recommendations[self.recommendations['user_id'] == user_id].head(k)\n",
    "            recommended_items = user_recs['video_id'].values\n",
    "            \n",
    "            # Obtenir les items pertinents (interactions positives) pour cet utilisateur dans le test\n",
    "            relevant_items = set(self.test_data[(self.test_data['user_id'] == user_id) & \n",
    "                                               (self.test_data['positive_interaction'] == 1)]['video_id'].values)\n",
    "            \n",
    "            # Calculer le DCG\n",
    "            dcg = 0\n",
    "            for i, item in enumerate(recommended_items):\n",
    "                rel = 1 if item in relevant_items else 0\n",
    "                dcg += rel / np.log2(i + 2)  # i+2 car i commence à 0\n",
    "            \n",
    "            # Calculer l'IDCG (DCG idéal)\n",
    "            idcg = 0\n",
    "            for i in range(min(len(relevant_items), k)):\n",
    "                idcg += 1 / np.log2(i + 2)\n",
    "                \n",
    "            # Calculer le NDCG\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0\n",
    "            ndcg_scores.append(ndcg)\n",
    "        \n",
    "        # Calculer le NDCG moyen\n",
    "        mean_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "        \n",
    "        return mean_ndcg\n",
    "    \n",
    "    def calculate_map(self, k=10):\n",
    "        \"\"\"\n",
    "        Calcule le MAP@k (Mean Average Precision) pour les recommandations\n",
    "        \n",
    "        Args:\n",
    "            k: Nombre de recommandations à considérer\n",
    "            \n",
    "        Returns:\n",
    "            MAP à k\n",
    "        \"\"\"\n",
    "        print(f\"Calcul du MAP@{k}...\")\n",
    "        \n",
    "        ap_scores = []\n",
    "        \n",
    "        # Pour chaque utilisateur dans les recommandations\n",
    "        for user_id in self.recommendations['user_id'].unique():\n",
    "            # Obtenir les top-k recommandations pour cet utilisateur\n",
    "            user_recs = self.recommendations[self.recommendations['user_id'] == user_id].head(k)\n",
    "            recommended_items = user_recs['video_id'].values\n",
    "            \n",
    "            # Obtenir les items pertinents pour cet utilisateur dans le test\n",
    "            relevant_items = set(self.test_data[(self.test_data['user_id'] == user_id) & \n",
    "                                               (self.test_data['positive_interaction'] == 1)]['video_id'].values)\n",
    "            \n",
    "            # Calculer l'AP (Average Precision)\n",
    "            hits = 0\n",
    "            sum_precisions = 0\n",
    "            \n",
    "            for i, item in enumerate(recommended_items):\n",
    "                if item in relevant_items:\n",
    "                    hits += 1\n",
    "                    precision_at_i = hits / (i + 1)\n",
    "                    sum_precisions += precision_at_i\n",
    "            \n",
    "            ap = sum_precisions / len(relevant_items) if len(relevant_items) > 0 else 0\n",
    "            ap_scores.append(ap)\n",
    "        \n",
    "        # Calculer le MAP\n",
    "        mean_ap = np.mean(ap_scores) if ap_scores else 0\n",
    "        \n",
    "        return mean_ap\n",
    "    \n",
    "    def calculate_coverage(self):\n",
    "        \"\"\"\n",
    "        Calcule la couverture du catalogue - pourcentage des vidéos qui sont recommandées\n",
    "        \n",
    "        Returns:\n",
    "            Pourcentage de couverture\n",
    "        \"\"\"\n",
    "        print(\"Calcul de la couverture...\")\n",
    "        \n",
    "        # Nombre total de vidéos disponibles\n",
    "        all_videos = set(self.model_data['content_features'].index)\n",
    "        \n",
    "        # Vidéos recommandées\n",
    "        recommended_videos = set(self.recommendations['video_id'].values)\n",
    "        \n",
    "        # Calculer la couverture\n",
    "        coverage = len(recommended_videos) / len(all_videos) if len(all_videos) > 0 else 0\n",
    "        \n",
    "        return coverage * 100  # En pourcentage\n",
    "    \n",
    "    def evaluate(self, ks=[5, 10, 20]):\n",
    "        \"\"\"\n",
    "        Évalue le modèle avec plusieurs métriques à différentes valeurs de k\n",
    "        \n",
    "        Args:\n",
    "            ks: Liste des valeurs de k à évaluer\n",
    "        \"\"\"\n",
    "        print(\"Évaluation du modèle...\")\n",
    "        \n",
    "        # Charger le modèle et les données de test si ce n'est pas déjà fait\n",
    "        if self.model_data is None:\n",
    "            self.load_model()\n",
    "        if self.test_data is None:\n",
    "            self.load_test_data()\n",
    "        \n",
    "        # Générer les recommandations si ce n'est pas déjà fait\n",
    "        if self.recommendations is None:\n",
    "            self.generate_recommendations(top_n=max(ks))\n",
    "        \n",
    "        # Stocker les résultats\n",
    "        results = {\n",
    "            'k': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'ndcg': [],\n",
    "            'map': []\n",
    "        }\n",
    "        \n",
    "        # Calculer les métriques pour chaque valeur de k\n",
    "        for k in ks:\n",
    "            results['k'].append(k)\n",
    "            results['precision'].append(self.calculate_precision_at_k(k))\n",
    "            results['recall'].append(self.calculate_recall_at_k(k))\n",
    "            results['ndcg'].append(self.calculate_ndcg_at_k(k))\n",
    "            results['map'].append(self.calculate_map(k))\n",
    "        \n",
    "        # Calculer la couverture\n",
    "        coverage = self.calculate_coverage()\n",
    "        \n",
    "        # Afficher les résultats\n",
    "        print(\"\\n===== Résultats de l'évaluation =====\")\n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(results_df)\n",
    "        print(f\"Couverture du catalogue: {coverage:.2f}%\")\n",
    "        \n",
    "        # Sauvegarder les résultats\n",
    "        results_df.to_csv('evaluation_results.csv', index=False)\n",
    "        \n",
    "        # Visualiser les résultats\n",
    "        self.plot_evaluation_results(results_df)\n",
    "        \n",
    "        return results_df, coverage\n",
    "    \n",
    "    def plot_evaluation_results(self, results_df):\n",
    "        \"\"\"\n",
    "        Visualise les résultats de l'évaluation\n",
    "        \n",
    "        Args:\n",
    "            results_df: DataFrame contenant les résultats\n",
    "        \"\"\"\n",
    "        print(\"Création des visualisations...\")\n",
    "        \n",
    "        # Configurer le style\n",
    "        plt.style.use('ggplot')\n",
    "        \n",
    "        # Créer une figure avec plusieurs sous-graphiques\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Précision@k\n",
    "        axes[0, 0].plot(results_df['k'], results_df['precision'], 'o-', color='blue')\n",
    "        axes[0, 0].set_title('Précision@k')\n",
    "        axes[0, 0].set_xlabel('k')\n",
    "        axes[0, 0].set_ylabel('Précision')\n",
    "        \n",
    "        # Rappel@k\n",
    "        axes[0, 1].plot(results_df['k'], results_df['recall'], 'o-', color='green')\n",
    "        axes[0, 1].set_title('Rappel@k')\n",
    "        axes[0, 1].set_xlabel('k')\n",
    "        axes[0, 1].set_ylabel('Rappel')\n",
    "        \n",
    "        # NDCG@k\n",
    "        axes[1, 0].plot(results_df['k'], results_df['ndcg'], 'o-', color='red')\n",
    "        axes[1, 0].set_title('NDCG@k')\n",
    "        axes[1, 0].set_xlabel('k')\n",
    "        axes[1, 0].set_ylabel('NDCG')\n",
    "        \n",
    "        # MAP@k\n",
    "        axes[1, 1].plot(results_df['k'], results_df['map'], 'o-', color='purple')\n",
    "        axes[1, 1].set_title('MAP@k')\n",
    "        axes[1, 1].set_xlabel('k')\n",
    "        axes[1, 1].set_ylabel('MAP')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evaluation_metrics.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Visualisations sauvegardées!\")\n",
    "\n",
    "    def analyze_recommendations(self):\n",
    "        \"\"\"\n",
    "        Analyse plus approfondie des recommandations générées\n",
    "        \"\"\"\n",
    "        print(\"Analyse des recommandations...\")\n",
    "        \n",
    "        if self.recommendations is None:\n",
    "            print(\"Aucune recommandation disponible. Veuillez d'abord générer des recommandations.\")\n",
    "            return\n",
    "        \n",
    "        # 1. Distribution des scores de recommandation\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(self.recommendations['score'], bins=30, kde=True)\n",
    "        plt.title('Distribution des scores de recommandation')\n",
    "        plt.xlabel('Score')\n",
    "        plt.ylabel('Fréquence')\n",
    "        plt.savefig('recommendation_scores_distribution.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Top vidéos les plus recommandées\n",
    "        top_videos = self.recommendations['video_id'].value_counts().head(20)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=top_videos.index.astype(str), y=top_videos.values)\n",
    "        plt.title('Top 20 des vidéos les plus recommandées')\n",
    "        plt.xlabel('ID Vidéo')\n",
    "        plt.ylabel('Nombre de recommandations')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('top_recommended_videos.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Calculer la diversité des recommandations par utilisateur\n",
    "        user_diversity = []\n",
    "        \n",
    "        for user_id in self.recommendations['user_id'].unique():\n",
    "            user_recs = self.recommendations[self.recommendations['user_id'] == user_id]\n",
    "            \n",
    "            # Si les caractéristiques des vidéos sont disponibles, on peut calculer une diversité plus précise\n",
    "            if 'content_features' in self.model_data:\n",
    "                # Extraire les caractéristiques des vidéos recommandées\n",
    "                video_features = self.model_data['content_features'].loc[user_recs['video_id']]\n",
    "                \n",
    "                # Calculer la diversité comme la variance moyenne des caractéristiques\n",
    "                diversity = video_features.var(axis=0).mean()\n",
    "                user_diversity.append(diversity)\n",
    "        \n",
    "        if user_diversity:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(user_diversity, bins=20, kde=True)\n",
    "            plt.title('Diversité des recommandations par utilisateur')\n",
    "            plt.xlabel('Diversité')\n",
    "            plt.ylabel('Fréquence')\n",
    "            plt.savefig('recommendation_diversity.png')\n",
    "            plt.close()\n",
    "        \n",
    "        print(\"Analyse terminée. Les visualisations ont été sauvegardées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48adc793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle depuis content_based_model.pkl...\n",
      "Modèle chargé!\n",
      "Chargement des données de test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75003/4228562612.py:43: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.test_data = pd.read_csv('interactions_test.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données de test chargées: (935314, 9)\n",
      "Génération des recommandations (top-10)...\n",
      "Recommandations générées: (14110, 3)\n",
      "Temps d'exécution: 14.52 secondes\n",
      "Évaluation du modèle...\n",
      "Calcul de la précision@5...\n",
      "Calcul du rappel@5...\n",
      "Calcul du NDCG@5...\n",
      "Calcul du MAP@5...\n",
      "Calcul de la précision@10...\n",
      "Calcul du rappel@10...\n",
      "Calcul du NDCG@10...\n",
      "Calcul du MAP@10...\n",
      "Calcul de la précision@20...\n",
      "Calcul du rappel@20...\n",
      "Calcul du NDCG@20...\n",
      "Calcul du MAP@20...\n",
      "Calcul de la couverture...\n",
      "\n",
      "===== Résultats de l'évaluation =====\n",
      "    k  precision    recall      ndcg       map\n",
      "0   5   0.344862  0.003803  0.332170  0.002320\n",
      "1  10   0.362580  0.008021  0.348884  0.004213\n",
      "2  20   0.362580  0.008021  0.225158  0.004213\n",
      "Couverture du catalogue: 6.15%\n",
      "Création des visualisations...\n",
      "Visualisations sauvegardées!\n",
      "Analyse des recommandations...\n",
      "Analyse terminée. Les visualisations ont été sauvegardées.\n",
      "Évaluation et analyse terminées.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    evaluator = RecommenderEvaluator()\n",
    "    evaluator.load_model()\n",
    "    evaluator.load_test_data()\n",
    "    evaluator.generate_recommendations(top_n=10)\n",
    "    results, coverage = evaluator.evaluate(ks=[5, 10, 20])\n",
    "    evaluator.analyze_recommendations()\n",
    "    print(\"Évaluation et analyse terminées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c6bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender-system-lectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
