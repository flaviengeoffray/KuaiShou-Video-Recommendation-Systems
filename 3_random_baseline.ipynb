{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e7b34b",
   "metadata": {},
   "source": [
    "### Random Baseline: Overview and Motivation\n",
    "\n",
    "**Random recommendation** is the simplest possible recommendation approach where items are suggested to users completely at random, without considering user preferences or item attributes. While this approach has no practical use in production systems, it serves as a crucial **baseline** for evaluating other recommendation algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Use Random Recommendations as a Baseline?\n",
    "\n",
    "- **Minimum performance threshold**: Any useful recommendation algorithm should significantly outperform random recommendations.\n",
    "- **Sanity check**: Ensures that evaluation metrics and experimental setup are functioning correctly.\n",
    "- **Identifies data biases**: Unexpectedly high performance from random recommendations can reveal hidden biases in the evaluation setup.\n",
    "- **Quantifies improvements**: Provides a reference point to measure the absolute improvement of more sophisticated approaches.\n",
    "- **Computation reference**: Demonstrates the trade-off between algorithmic complexity and performance gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d39ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_PATH = 'data_final_project/KuaiRec 2.0/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15888ea",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6aaed3",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "The recommendation system is based on several CSV files that represent user interactions and video metadata:\n",
    "\n",
    "---\n",
    "\n",
    "#### `big_matrix.csv`\n",
    "- Contains historical **user-video interactions**.\n",
    "- Used for **training** user profiles.\n",
    "- Includes fields like: `user_id`, `video_id`, `watch_ratio`, `play_duration`, etc.\n",
    "\n",
    "#### `small_matrix.csv`\n",
    "- Contains **test interactions**, recorded after the training period.\n",
    "- Used to **evaluate** recommendation quality.\n",
    "\n",
    "For our baseline random recommender, we only need the basic interaction data to identify which videos are available for recommendation and which users we should generate recommendations for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877364cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train interactions: (12530806, 8)\n",
      "Test interactions: (4676570, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\t\t\n",
    "# Load interaction data\n",
    "interactions_train = pd.read_csv(os.path.join(DATA_PATH, \"big_matrix.csv\"))\n",
    "interactions_test = pd.read_csv(os.path.join(DATA_PATH, \"small_matrix.csv\"))\n",
    "\n",
    "print(f\"Train interactions: {interactions_train.shape}\")\n",
    "print(f\"Test interactions: {interactions_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c45bc",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a457fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactions_train: 12530806 rows -> 11564987 rows (965819 removed)\n",
      "interactions_test: 4676570 rows -> 4494578 rows (181992 removed)\n",
      "Positive interactions in train set: 5966291 / 11564987 (51.59%)\n",
      "Positive interactions in test set: 2536880 / 4494578 (56.44%)\n",
      "Number of unique users: 7176\n",
      "Number of unique videos: 10728\n",
      "Data loaded and preprocessed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Show differences before and after dropna and drop_duplicates\n",
    "\n",
    "def preprocess(df, name):\n",
    "    before = df.shape[0]\n",
    "    after = df.dropna().drop_duplicates().shape[0]\n",
    "    print(f\"{name}: {before} rows -> {after} rows ({before - after} removed)\")\n",
    "    return df.dropna().drop_duplicates()\n",
    "\n",
    "interactions_train = preprocess(interactions_train, \"interactions_train\")\n",
    "interactions_test = preprocess(interactions_test, \"interactions_test\")\n",
    "\n",
    "# Process watch_ratio - clamp extreme values to keep them in a reasonable range\n",
    "# Normally, a watch_ratio > 1 can indicate replays, but clamp to 2.0 as a reasonable max value\n",
    "interactions_train['watch_ratio_clamped'] = np.clip(interactions_train['watch_ratio'], 0, 2.0)\n",
    "interactions_test['watch_ratio_clamped'] = np.clip(interactions_test['watch_ratio'], 0, 2.0)\n",
    "\n",
    "# Adjust the positive interaction threshold based on data analysis\n",
    "POSITIVE_THRESHOLD = 0.7\n",
    "interactions_train['positive_interaction'] = (interactions_train['watch_ratio_clamped'] >= POSITIVE_THRESHOLD).astype(int)\n",
    "interactions_test['positive_interaction'] = (interactions_test['watch_ratio_clamped'] >= POSITIVE_THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"Positive interactions in train set: {interactions_train['positive_interaction'].sum()} / {len(interactions_train)} ({interactions_train['positive_interaction'].mean()*100:.2f}%)\")\n",
    "print(f\"Positive interactions in test set: {interactions_test['positive_interaction'].sum()} / {len(interactions_test)} ({interactions_test['positive_interaction'].mean()*100:.2f}%)\")\n",
    "\n",
    "# Get unique users and videos\n",
    "unique_users = interactions_train['user_id'].unique()\n",
    "all_videos = interactions_train['video_id'].unique()\n",
    "\n",
    "print(f\"Number of unique users: {len(unique_users)}\")\n",
    "print(f\"Number of unique videos: {len(all_videos)}\")\n",
    "\n",
    "# Create user and video ID maps for quick reference\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "video_id_map = {video_id: idx for idx, video_id in enumerate(all_videos)}\n",
    "\n",
    "print(\"Data loaded and preprocessed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f17ed",
   "metadata": {},
   "source": [
    "### Random Recommendation Implementation\n",
    "\n",
    "The `generate_random_recommendations()` function simply selects videos at random to recommend to users. Unlike content-based or collaborative approaches, no user profile or similarity computation is needed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Features:\n",
    "\n",
    "- **Pure randomness**: Recommendations are completely unbiased and unpersonalized.\n",
    "- **Optional exclusion**: Can exclude videos the user has already watched.\n",
    "- **Baseline performance**: Establishes the minimum effectiveness for any recommendation algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why it matters:\n",
    "\n",
    "Random recommendations serve as a performance floor - any algorithm that cannot outperform random recommendations is not providing meaningful personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ef461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random recommendations for user 0: [(6156, 0.22321073814882275), (6259, 0.7364712141640124), (4194, 0.6766994874229113), (532, 0.8921795677048454), (4524, 0.08693883262941615)]\n",
      "Random recommendations for user 1: [(5505, 0.2326608933907396), (8516, 0.6020187290499803), (4266, 0.561245062938613), (674, 0.7160196129224035), (2496, 0.7013249735902359)]\n",
      "Random recommendations for user 2: [(6561, 0.8094304566778266), (2574, 0.006498759678061017), (9979, 0.8058192518328079), (9230, 0.6981393949882269), (1519, 0.3402505165179919)]\n",
      "Random recommendations for user 3: [(7105, 0.3799273006373374), (9828, 0.3589793804846284), (6120, 0.3439557224789711), (1431, 0.26452086722201307), (7376, 0.04345044292309719)]\n",
      "Random recommendations for user 4: [(9327, 0.552040631273227), (10048, 0.8294046642529949), (10409, 0.6185197523642461), (6867, 0.8617069003107772), (4167, 0.577352145256762)]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_recommendations(user_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Generate random recommendations for a user.\n",
    "    \"\"\"\n",
    "    # Check if user exists in our data\n",
    "    if user_id not in user_id_map:\n",
    "        print(f\"User {user_id} not found in training data\")\n",
    "        return []\n",
    "\n",
    "    return [(video_id, random.random()) for video_id in random.sample(list(all_videos), top_n)]\n",
    "\n",
    "# Example recommendations for a few users\n",
    "for user_id in unique_users[:5]:\n",
    "    recommendations = generate_random_recommendations(user_id, top_n=5)\n",
    "    print(f\"Random recommendations for user {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f08c7",
   "metadata": {},
   "source": [
    "### Evaluation: Ranking Quality on Test Videos\n",
    "\n",
    "To ensure a fair comparison with the content-based approach, we use the exact same evaluation methodology. This function evaluates how well the random recommender system ranks videos that the user has **actually seen** in the test set.\n",
    "\n",
    "---\n",
    "\n",
    "#### Metrics Computed:\n",
    "\n",
    "For each user, the following metrics are computed at `k` (typically 5, 10, or 20):\n",
    "\n",
    "| Metric        | Definition                                                                 |\n",
    "|---------------|---------------------------------------------------------------------------|\n",
    "| `Precision@k` | Fraction of top-k recommended videos that are truly liked                 |\n",
    "| `Recall@k`    | Fraction of all liked videos that appear in the top-k                     |\n",
    "| `NDCG@k`      | Discounted cumulative gain, rewarding relevant items near the top of the list |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b491b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random baseline evaluation on test videos... (top-5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 1411/1411 [00:29<00:00, 47.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users evaluated: 1411 / 1411\n",
      "Users skipped: 0\n",
      "Expected random precision: 0.169234\n",
      "Actual precision: 0.164989\n",
      "Precision ratio (actual/expected): 0.9749198327906096\n",
      "\n",
      "Random Baseline Results at k=5:\n",
      "Precision@5: 0.1650 (expected: 0.1692)\n",
      "Recall@5:    0.0005\n",
      "NDCG@5:      0.3773\n",
      "Users evaluated:   1411\n",
      "Random baseline evaluation on test videos... (top-10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 1411/1411 [00:30<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users evaluated: 1411 / 1411\n",
      "Users skipped: 0\n",
      "Expected random precision: 0.169234\n",
      "Actual precision: 0.167257\n",
      "Precision ratio (actual/expected): 0.9883207926915115\n",
      "\n",
      "Random Baseline Results at k=10:\n",
      "Precision@10: 0.1673 (expected: 0.1692)\n",
      "Recall@10:    0.0009\n",
      "NDCG@10:      0.4517\n",
      "Users evaluated:   1411\n",
      "Random baseline evaluation on test videos... (top-20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 1411/1411 [00:31<00:00, 45.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users evaluated: 1411 / 1411\n",
      "Users skipped: 0\n",
      "Expected random precision: 0.169234\n",
      "Actual precision: 0.167824\n",
      "Precision ratio (actual/expected): 0.991671032666737\n",
      "\n",
      "Random Baseline Results at k=20:\n",
      "Precision@20: 0.1678 (expected: 0.1692)\n",
      "Recall@20:    0.0019\n",
      "NDCG@20:      0.4942\n",
      "Users evaluated:   1411\n"
     ]
    }
   ],
   "source": [
    "def evaluate_random_model(k=10, positive_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Evaluate the ranking quality of random recommendations on test videos.\n",
    "    \"\"\"\n",
    "    print(f\"Random baseline evaluation on test videos... (top-{k})\")\n",
    "\n",
    "    test_users = interactions_test['user_id'].unique()\n",
    "    test_users = [u for u in test_users if u in user_id_map]\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    ndcg_list = []\n",
    "    skipped = 0\n",
    "\n",
    "    for user_id in tqdm(test_users, desc=\"Evaluating users\"):\n",
    "        # Don't filter by videos in training set - include all test videos\n",
    "        user_test_data = interactions_test[interactions_test['user_id'] == user_id]\n",
    "\n",
    "        if user_test_data.empty:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Ground truth: all liked videos in test set (not just ones from training)\n",
    "        positive_videos = set(\n",
    "            user_test_data[user_test_data['watch_ratio_clamped'] >= positive_threshold]['video_id']\n",
    "        )\n",
    "\n",
    "        if len(positive_videos) == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Get all unique videos from both training and test sets\n",
    "        all_possible_videos = np.union1d(all_videos, interactions_test['video_id'].unique())\n",
    "        \n",
    "        # Modified random recommendation function that samples from ALL possible videos\n",
    "        # This ensures we're truly measuring random recommendations\n",
    "        recommendations = [(video_id, random.random()) \n",
    "                           for video_id in random.sample(list(all_possible_videos), min(k, len(all_possible_videos)))]\n",
    "        \n",
    "        ranked_video_ids = [vid for vid, _ in recommendations]\n",
    "\n",
    "        recommended_set = set(ranked_video_ids)\n",
    "        intersection = positive_videos & recommended_set\n",
    "\n",
    "        precision = len(intersection) / len(ranked_video_ids)\n",
    "        recall = len(intersection) / len(positive_videos) if len(positive_videos) > 0 else 0\n",
    "        relevance = [1 if vid in positive_videos else 0 for vid in ranked_video_ids]\n",
    "        ndcg = ndcg_score([relevance], [list(range(len(ranked_video_ids), 0, -1))]) if any(relevance) else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        ndcg_list.append(ndcg)\n",
    "\n",
    "    print(f\"Users evaluated: {len(precision_list)} / {len(test_users)}\")\n",
    "    print(f\"Users skipped: {skipped}\")\n",
    "    \n",
    "    # Calculate expected random precision (theoretical value)\n",
    "    all_possible_videos = np.union1d(all_videos, interactions_test['video_id'].unique())\n",
    "    avg_positive_per_user = np.mean([\n",
    "        len(interactions_test[(interactions_test['user_id'] == u) & \n",
    "                              (interactions_test['positive_interaction'] == 1)]['video_id'].unique())\n",
    "        for u in test_users[:100]  # Sample for efficiency\n",
    "    ])\n",
    "    expected_precision = avg_positive_per_user / len(all_possible_videos)\n",
    "    \n",
    "    print(f\"Expected random precision: {expected_precision:.6f}\")\n",
    "    print(f\"Actual precision: {np.mean(precision_list):.6f}\")\n",
    "    print(f\"Precision ratio (actual/expected): {np.mean(precision_list)/expected_precision if expected_precision > 0 else 'N/A'}\")\n",
    "\n",
    "    return {\n",
    "        'precision@k': np.mean(precision_list),\n",
    "        'recall@k': np.mean(recall_list),\n",
    "        'ndcg@k': np.mean(ndcg_list),\n",
    "        'expected_precision': expected_precision,\n",
    "        'users_evaluated': len(precision_list)\n",
    "    }\n",
    "\n",
    "# Evaluate at different k values\n",
    "for k_value in [5, 10, 20]:\n",
    "    results = evaluate_random_model(k=k_value, positive_threshold=0.7)\n",
    "    print(f\"\\nRandom Baseline Results at k={k_value}:\")\n",
    "    print(f\"Precision@{k_value}: {results['precision@k']:.4f} (expected: {results['expected_precision']:.4f})\")\n",
    "    print(f\"Recall@{k_value}:    {results['recall@k']:.4f}\")\n",
    "    print(f\"NDCG@{k_value}:      {results['ndcg@k']:.4f}\")\n",
    "    print(f\"Users evaluated:   {results['users_evaluated']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
